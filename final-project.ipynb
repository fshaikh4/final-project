{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Template "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Get your data\n",
    "You may use any data set(s) you like, so long as they meet these criteria:\n",
    "\n",
    "* Your data must be publically available for free.\n",
    "* Your data should be interesting to _you_. You want your final project to be something you're proud of.\n",
    "* Your data should be \"big enough\":\n",
    "    - It should have at least 1,000 rows.\n",
    "    - It should have enough of columns to be interesting.\n",
    "    - If you have questions, contact a member of the instructional team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Provide a link to your data\n",
    "Your data is required to be free and open to anyone.\n",
    "As such, you should have a URL which anyone can use to download your data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Dallas Lifespan Brain Study (DLBS)](http://fcon_1000.projects.nitrc.org/indi/retro/dlbs.html): _all data files are in .tar.gz format_\n",
    " - [Cognitive data](ftp://www.nitrc.org/fcon_1000/htdocs/indi/retro/dlbs_content/dlbs_cogdata.tar.gz)\n",
    " - [Neuroimaging data](ftp://www.nitrc.org/fcon_1000/htdocs/indi/retro/dlbs_content/dlbs_imaging.tar.gz)\n",
    "  - [Anatomical scan parameters](ftp://www.nitrc.org/fcon_1000/htdocs/indi/retro/dlbs_content/dlbs_scan_params_anat.pdf)\n",
    "  - [PET scan parameters](ftp://www.nitrc.org/fcon_1000/htdocs/indi/retro/dlbs_content/dlbs_scan_params_pet.pdf)\n",
    " - [Genetic data](ftp://www.nitrc.org/fcon_1000/htdocs/indi/retro/dlbs_content/dlbs_genetics.tar.gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Import your data\n",
    "In the space below, import your data.\n",
    "If your data span multiple files, read them all in.\n",
    "If applicable, merge or append them as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "from pathlib import Path # path management\n",
    "import ftplib # ftp server access for source data file download\n",
    "import time # operation timers\n",
    "import tarfile # read tar.gz archive source data files\n",
    "import pandas as pd # data wrangling and tabular representation\n",
    "import seaborn as sb # data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/faysal/fshaikh4-GitHub/final-project')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return current working directory\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data import via `FTP` module below has been commented-out due to issues downloading neuroimaging dataset.\n",
    "\n",
    "As an alternative, appropriate files (in their unmodified `.tar.gz` archive format) were copied and pasted into `./data/` and utilized in downstream prepreprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create './data/' dir in cwd, if not existing (but do not overwrite)\n",
    "# Path('./data/').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify URLs for source data files\n",
    "ftp_url = 'www.nitrc.org'\n",
    "ftp_path = 'fcon_1000/htdocs/indi/retro/dlbs_content/'\n",
    "\n",
    "cog_fname = 'dlbs_cogdata.tar.gz'\n",
    "ni_fname = 'dlbs_imaging.tar.gz'\n",
    "gen_fname = 'dlbs_genetics.tar.gz'\n",
    "\n",
    "anat_parm_fname = 'dlbs_scan_params_anat.pdf'\n",
    "pet_parm_fname = 'dlbs_scan_params_pet.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start timer object\n",
    "# t_i = time.time()\n",
    "\n",
    "# # use FTP to access and download source data files (ONCE ONLY)\n",
    "# ftp = ftplib.FTP(ftp_url)\n",
    "# ftp.login()\n",
    "# ftp.cwd(ftp_path)\n",
    "# ftp.retrbinary('RETR ' + cog_fname, open('./data/' + cog_fname, 'wb').write)\n",
    "# ftp.retrbinary('RETR ' + ni_fname, open('./data/' + ni_fname, 'wb').write)\n",
    "# ftp.retrbinary('RETR ' + gen_fname, open('./data/' + gen_fname, 'wb').write)\n",
    "# ftp.retrbinary('RETR ' + anat_parm_fname, open('./data/' + anat_parm_fname, 'wb').write)\n",
    "# ftp.retrbinary('RETR ' + pet_parm_fname, open('./data/' + pet_parm_fname, 'wb').write)\n",
    "# ftp.quit();\n",
    "\n",
    "# # end timer object\n",
    "# t_f = time.time()\n",
    "\n",
    "# # print elapsed time\n",
    "# print('Time elapsed: '+str(t_f - t_i)+' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After obtaining relevant data files in raw `.tar.gz` archive file format, relevant data were extracted and utilized in downstream preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create extracted data subdirectories\n",
    "Path('./data/cogdata/').mkdir(exist_ok=True) # create dir if not existing\n",
    "Path('./data/imaging/').mkdir(exist_ok=True) # create dir if not existing\n",
    "Path('./data/genetics/').mkdir(exist_ok=True) # create dir if not existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract relevant data files from .tar.gz archives\n",
    "import tarfile\n",
    "\n",
    "# extract cognitive data\n",
    "tar = tarfile.open('./data/'+cog_fname, 'r:gz')\n",
    "tar.extractall(path = './data/cogdata/')\n",
    "tar.close()\n",
    "\n",
    "# extract neuroimaging data\n",
    "tar = tarfile.open('./data/'+ni_fname, 'r:gz')\n",
    "tar.extractall(path = './data/imaging/')\n",
    "tar.close()\n",
    "\n",
    "# extract genetics data\n",
    "tar = tarfile.open('./data/'+gen_fname, 'r:gz')\n",
    "tar.extractall(path = './data/genetics/')\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in each data file into individual pandas.DataFrame objects\n",
    "# cog_data = pd.read_table('./data/' + cog_fname, sep='\\t')\n",
    "# ni_data = pd.read_table('./data/' + ni_fname, sep='\\t')\n",
    "# gen_data = pd.read_table('./data/' + gen_data, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data into single consolidated pandas.DataFrame object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize neuroimaging data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Show me the head of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Show me the shape of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Show me the proportion of missing observations for each column of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Give me a problem statement.\n",
    "Below, write a problem statement. Keep in mind that your task is to tease out relationships in your data and eventually build a predictive model. Your problem statement can be vague, but you should have a goal in mind. Your problem statement should be between one sentence and one paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(placeholder cell to fill in later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) What is your _y_-variable?\n",
    "For final project, you will need to perform a statistical model. This means you will have to accurately predict some y-variable for some combination of x-variables. From your problem statement in part 7, what is that y-variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(placeholder cell to fill in later)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
